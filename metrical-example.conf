# This is the sample configuration file for metrical.
[log]
  ## Logging configuration
  ## 'stdout' enables logging to standard output
  stdout = true
  
  ## 'filename' is the path to the log file
  ## if empty, logging to file is disabled
  filename = "./metrical.log"
  
  ## 'level' sets the logging level
  ## valid levels are: DEBUG, INFO, WARN, ERROR
  level = "INFO"

[http]
  ## HTTP server configuration
  ## 'listen' is the address to bind to (e.g. ":3000" for all interfaces on port 3000)
  ## if listen is empty, no HTTP server will be started
  listen = ":3000"
  ## 'adv_addr' is the address to advertise to clients (e.g. "http://myhost:3000")
  adv_addr = "http://localhost:3000"
  ## 'dashboard' is the path to the dashboard (e.g. "/dashboard")
  ## if 'dashboard' is empty, no dashboard will be served
  [[http.dashboard]]
    path = "/dashboard"
  ##
  ## tails
  # [[http.tail]]
  #   path = "/term/logs"
  #   [[http.tail.file]]
  #     filename = "${log-filename}"
  #     label = "metrical"
  #     highlights = ["level", "slog-text"]
  #   [[http.tail.file]]
  #     filename = "/var/log/syslog"
  #     label = "syslog"
  #     highlights = ["syslog", "level"]
  #   [[http.tail.file]]
  #     filename = "/var/log/auth.log"
  #     label = "auth.log"
  #     highlights = ["level"]
  #[[http.term]]
  #  path = "/term/home"
  #  command = "/usr/bin/zsh"
  #  args = ["-il"]
  #  dir = "/home/user_id"
  #[[http.term]]
  #  path = "/term/htop"
  #  command = "/usr/bin/htop"
  #  args = []
  #  dir = "/home/user_id"
  #[[http.ssh]]
  #  path = "/term/ssh-host"
  #  host ="your.ssh.host"
  #  port = 22
  #  user = "your_id"
  #  password = "your_password_here"
  #  keyfile = "/home/your_id/.ssh/id_rsa"
  ##
  ## If 'ssh.command' is empty, it will start a shell session
  ## otherwise, it will run the specified command upon connection
  #  command = "tail -F /var/log/syslog"

[data]
  sampling_interval = "10s"
  input_buffer = 1000

  ## optional prefix for all timeseries names
  ## it will be prepended to the name of metrics for publish to expvar
  ## refer to https://pkg.go.dev/expvar for details
  prefix = ""

  ## persistence store configuration
  ## if empty, no persistence will be used (in-memory only)
  # store = "sqlite:/path/to/metrical.db"
  store = ""

  [data.filter]
    includes = []
    excludes = []

  ## Define the timeseries to be collected and stored
  ## 'id' is a unique identifier for the timeseries, It must start with a letter and
  ##      can contain only uppercase letters, numbers, and underscores.
  ## 'title' is a human-readable name for the timeseries.
  ## 'interval' is the sampling interval for the timeseries (e.g. "10s" for 10 seconds)
  ## 'length' is the number of data points to retain in the timeseries.
  [[data.timeseries]]
    id = "TS_10S"
    title = "15 Minutes of 10 sec"
    interval = "10s"
    length = 90 # 15 minutes

  [[data.timeseries]]
    id = "TS_1M"
    title = "4 Hours of 1 min"
    interval = "60s"
    length = 240 # 4 hours

  [[data.timeseries]]
    id = "TS_1H"
    title = "10 Days of 1 hour"
    interval = "60m"
    length = 240 # 10 days

  [[data.timeseries]]
    id = "TS_1D"
    title = "480 Days of 1 day"
    interval = "24h"
    length = 240 # 480 days


[[input.cpu]]
  ## collect per CPU stats, default false
  per_cpu = false


[[input.disk]]
  ## By default stats will be gathered for all mount points.
  ## Set mount_points will restrict the stats to only the specified mount points.
  # mount_points = ["/"]

  ## Ignore mount points by filesystem type.
  ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs"]

  ## Ignore mount points by mount options.
  ## The 'mount' command reports options of all mounts in parenthesis.
  ## Bind mounts can be ignored with the special 'bind' option.
  # ignore_mount_opts = []

  ## metrics of disk I/O stats to monitor, empty for all (default)
  ## Metric Names
  ##     disk:<mount_points>:<metric>
  ##
  ## Available metrics:
  ##    total, free, used, used_percent,
  ##    inodes_total, inodes_free, inodes_used, inodes_used_percent
  ##
    [input.disk.filter]
      includes = ["disk:*:used_percent"]
      excludes = []

[[input.diskio]]
  ## Block devices to monitor, empty for all devices (default)
  ## e.g., devices = ["sd*", "vd*", "xvd*"]
  devices = ["*"]

  ## metrics of disk I/O stats to monitor, empty for all (default)
  ## Metric Names
  ##     diskio:<device>:<metric>
  ##
  ## Available metrics:
  ##
  ## read_bytes, write_bytes,
  ## read_time, write_time,
  ## read_merged, write_merged,
  ## read_ios, write_ios,
  ## io_in_progress,
  ## io_time, weighted_io_time
  ##
  # [input.diskio.filter]
    ## Include only these kinds of disk I/O stats, empty for all kinds (default)
    #includes = ["diskio:sda:read_*", "diskio:sda:write_*"]

    ## Exclude these kinds of disk I/O stats, empty for none (default)
    #excludes = ["diskio:*:*time"]


[[input.go_mem]]
  ## metrics of go runtime memory stats to monitor.
  ## Metric Names
  ##    go:mem:<metric>
  ##
  ## Available metrics:
  ##    heap_inuse


[[input.go_runtime]]
  ## metrics of go runtime stats to monitor.
  ## Metric Names
  ##    go:runtime:<metric>
  ##
  ## Available metrics:
  ##    goroutines
  

[[input.load]]
  ## metrics of load averages to monitor, empty for all (default)
  ## Metric Names
  ##     load:load1, load:load5, load:load15
  ##
  [input.load.filter]
    includes = ["load:load1", "load:load5", "load:load15"]
  # excludes = []

[[input.mem]]


#[[input.net]]
  ## Network interfaces to monitor, empty for all interfaces (default)
  interfaces = ["eth*", "en*"]

  ## Whether to report per-interface stats (true), or aggregate all interfaces (false, default)
  per_nic = false

  ## metrics of network traffics to monitor, empty for all (default)
  ## Metric Names
  ##     net:<interface>:<metric>
  ##   The total across all interfaces is reported with interface name "all"
  ##     net:all:<metric>
  ##
  ## Available metrics:
  ##
  ## bytes_sent, bytes_recv, packets_sent, packets_recv,
  ## err_in, err_out, drop_in, drop_out
  ## 
  [input.net.filter]
    ## Include only these kinds of network stats, empty for all kinds (default)
    includes = []  # ["net:*:bytes_*", "net:*:packets_*"]

    ## Exclude these kinds of network stats, empty for none (default)
    excludes = []  # ["net:*:*err_*", "net:*:*drop_*"]


#[[input.netstat]]

  ## metrics of netstat to monitor, empty for all (default)
  ## Metric Names
  ##     netstat:<metric>
  ##
  ## Available metrics:
  ##
  ## tcp_established, tcp_syn_sent, tcp_syn_recv, tcp_fin_wait1, tcp_fin_wait2,
  ## tcp_time_wait, tcp_close, tcp_close_wait, tcp_last_ack, tcp_listen,
  ## tcp_closing, tcp_none, udp_socket
  ##
  [input.netstat.filter]
    ## Include only these kinds of network stats, empty for all kinds (default)
    includes = []  # ["netstat:tcp_*", "netstat:udp_*"]
    ## Exclude these kinds of network stats, empty for none (default)
    excludes = []  # ["netstat:tcp_none"]

# [[input.opcua]]
  ## OPC UA server endpoint URL
  # endpoint = "opc.tcp://localhost:4840"

  ## Security mode, one of "None", "Sign", "SignAndEncrypt"
  # security_mode = "None"

  ## Security policy, one of
  ## "None", "Prefix", "Basic128Rsa15", "Basic256", 
  ## "Basic256Sha256", "Aes128_Sha256_RsaOaep", "Aes256_Sha256_RsaPss"
  ## 
  # security_policy = "None"

  ## Certificate file path for "SignAndEncrypt" mode
  # certificate = ""

  ## Private key file path for "SignAndEncrypt" mode
  # private_key = ""

  ## Connection retry interval
  # conn_retry_interval = "1s"

  ## If the retry count is set to 0, it will fail after the first attempt.
  # conn_retry_count = 0

  ## Read retry interval
  # read_retry_interval = "100ms"

  ## If the retry count is set to 0, it will fail after the first attempt.
  # read_retry_count = 0

  ## Node ID configuration
  ## name        - measurement name to use in the output
  ## namespace   - OPC UA namespace of the node (integer 0 ~ 3)
  ## id_type     - OPC UA ID type "s" (string), "i" (numeric), "g" (GUID), "b" (opaque)
  ## id          - OPC UA ID
  ##
  ## Use either the inline notation or the table notation, not both.

  ## Inline notation
  # nodes = [
  #   { name = "node1", namespace = "1", id_type = "s", id = "Temperature" },
  #   { name = "node2", namespace = "1", id_type = "s", id = "Pressure" }
  # ]

  ## Table notation
  # [[input.opcua.nodes]]
  #   name = "node1"
  #   namespace = "1"
  #   id_type = "s"
  #   id = "Temperature"
  #
  # [[input.opcua.nodes]]
  #   name = "node2"
  #   namespace = "1"
  #   id_type = "s"
  #   id = "Pressure"


#[[output.ndjson]]
  ## Destination URL to send ndjson encoded data to
  # This should be an endpoint that accepts HTTP POST requests with a body
  # containing newline-delimited JSON objects.
  # The Content-Type header will be set to "application/x-ndjson".
  # The URL should respond with a 2xx status code on success.
  #
  # if empty, will print to stdout
  ## Example:
  # e.g. "http://127.0.0.1:5654/db/write/TAG"
  dest = ""

  ## List of metric name patterns to include in the output
  ## If empty, all metrics will be included
  ## Patterns can include wildcards, e.g. "cpu:cpu_*" to include all cpu metrics
  #[output.ndjson.filter]
  #  includes = []
  #  excludes = []

  ## Time format to use for the "time" value in the output JSON objects
  ## See https://pkg.go.dev/time#Time.Format for details on the format
  # e.g.
  # "s" for seconds since epoch
  # "ms" for milliseconds since epoch
  # "us" for microseconds since epoch
  # "ns" for nanoseconds since epoch
  # "2006-01-02 15:04:05" for a common datetime format
  # "2006-01-02T15:04:05Z07:00" for RFC3339 format
  timeformat = "ns"

  ## For odometer type metrics, how to select the value to report
  # "diff" for difference since last value
  # "no_negative_diff" for no negative difference, if the difference is negative, report 0
  # "abs_diff" for absolute difference, useful for values that may wrap around
  odometer_value_selector = "diff"

  ## For histogram type metrics, which percentile value to report
  # e.g. 
  # 0 to report the first percentile (minimum)
  # 0.95 for 95th percentile
  # 0.5 for median
  histogram_value_selector = 0

